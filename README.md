MLflow MLOps Pipeline â€“ Assignment
ğŸ“Œ Project Overview

This project demonstrates a simple end-to-end MLOps workflow using:

MLflow Pipelines â€“ for reproducible pipeline steps

DVC (Data Version Control) â€“ for dataset tracking and remote storage

GitHub Actions / Jenkins â€“ for CI/CD automation

Python (scikit-learn) â€“ for model training and evaluation

The ML problem used in this assignment is the Boston Housing Regression Task, where the goal is to predict house prices based on 13 numerical input features.

The project includes:

Data extraction from DVC remote

Preprocessing (train/test split)

Model training (Linear Regression)

Evaluation and metrics logging

CI/CD pipeline for automatic validation

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone <your-repo-url>
cd mlops-kubeflow-assignment

2ï¸âƒ£ Create a Virtual Environment
Windows:
python -m venv venv
venv\Scripts\activate

Mac/Linux:
python3 -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install --upgrade pip
pip install -r requirements.txt

4ï¸âƒ£ DVC Setup

This project uses DVC to track the dataset stored remotely.

Initialize DVC

(Only run this if .dvc folder is missing)

dvc init

Add Remote Storage

Example (Google Drive / S3 / Local FS â€” depends on your instructor):

dvc remote add -d myremote <REMOTE-URL>


To pull dataset tracked by DVC:

dvc pull


This downloads:

data/raw/data.csv

5ï¸âƒ£ MLflow Setup

MLflow tracking runs locally using the default file store.

To start MLflow UI:

mlflow ui


Then visit:

http://127.0.0.1:5000

ğŸš€ Pipeline Walkthrough

The MLflow pipeline is implemented in two files:

src/pipeline_components.py â†’ load, preprocess, train, evaluate

pipeline.py â†’ orchestrates the full MLflow workflow

1ï¸âƒ£ Run the MLflow Pipeline

In the project root:

python pipeline.py


This performs:

âœ” Load dataset using DVC
âœ” Clean and preprocess
âœ” Split into train/test
âœ” Train Linear Regression
âœ” Save trained model (model.joblib)
âœ” Save evaluation metrics (metrics.txt)
âœ” Log all outputs to MLflow

Sample output:

Data loaded. Shape: (506, 14)
Train/Test split -> Train: (404, 13), Test: (102, 13)
Model trained and saved to model.joblib
Metrics saved to metrics.txt

2ï¸âƒ£ View MLflow Logs

Run:

mlflow ui


You will be able to see:

Model parameters

Metrics

Artifacts (model + plots + metrics)

3ï¸âƒ£ Continuous Integration (CI/CD)

You can run the pipeline automatically using:

GitHub Actions â†’ .github/workflows/mlflow-pipeline.yml

Jenkins â†’ Jenkinsfile

Each CI pipeline includes:

Environment Setup

Pipeline Execution

Tests & Validation

A successful run ensures your ML pipeline works end-to-end on every commit.

ğŸ“ Repository Structure
.
â”œâ”€â”€ data/               # DVC-tracked dataset
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline_components.py
â”œâ”€â”€ pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .dvc/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
